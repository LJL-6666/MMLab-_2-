通过本次课程的学习了解到书生提供了一个当前比较全的大模型架构平台。包括大模型的构建与训练，大模型智能体，多模态的大模型智能体。这些基础的开源平台使得更多人可以借助其做大模型的开发与部署应用工作。



internLM2-chat-20B有GPT3.5的能力，在多智能体链路中，GPT3.5的多智能体组合可以超过gpt4的能力，所以可以尝试一个internLM2-chat-20B组合一个Agent工作流程的水平如何。
1）Reflection：让 Agent 审视和修正自己生成的输出；
2）Tool Use：LLM 生成代码、调用 API 等进行实际操作；
3）Planning：让 Agent 分解复杂任务并按计划执行；
4）Multiagent Collaboration：多个 Agent 扮演不同角色合作完成任务；
单纯的比较gpt3.5与gpt4的编码能力，GPT-4 做得更好，正确率达到了 67.7%，但如果你围绕 GPT-3.5 使用一个 Agent 工作流程，实际上它的表现甚至比 GPT-4 还要好。如果你将这种类型的工作流程应用于 GPT-4，它也表现得非常好。你会注意到，GPT-3.5 与一个 Agent 性工作流程相结合实际上超过了 GPT-4 的表现。

[图片]

[图片]

以上的思路表明，如果智能体在复杂的场景表现的不够好，要么是RAG或者是微调，但是我们如上面的笔记，可以尝试构建一个智能体的工作流，也许可以更好的提高多个智能体组成的系统整体的效果，比微调更好，或者微调后建立这样的工作流效果又能够得到一个提升。

[图片]

[图片]

[图片]

如何保证增量续训不会遗忘之前的知识？这里有怎样的机制？
[图片]

[图片]

[图片]

[图片]
